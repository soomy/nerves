\begin{abstract}
The peripheral nervous system (PNS) is susceptible to be affected by peripheral neuropathies, which are prevalent with 2.4 up to 14.8 \%, rising with age, and can result in deficiencies or restrictions of sensory or motor abilities. 
Diagnosis and assessment of peripheral neuropathies traditionally rely on neurological examinations, which might provide inconclusive results or are not amenable to deeply situated peripheral nerves. 
Magnetic resonance neurography (MRN) has recently gained popularity as a complementary diagnostic tool for peripheral neuropathies. A problem, however, is that as of today MRN is qualitative because it is subjectively assessed by the radiologists. The use of MRN images to extract potential quantitative biomarkers, such as cross-sectional area and nerve compartment volume ratio has recently been proposed. However, a prerequisite for calculation of such biomarkers is the segmentation of the PNS, which is expensive and tedious work for radiologists, has reproducibility issues, and is not always clinically feasible. 

This thesis aimed to develop a fully-automatic deep learning-based approach to segment the sciatic nerve from thigh MRN images and to investigate the impact of 3-D context on the segmentation performance.
We retrospectively selected 52 thigh MRN cases separated into a patient cohort with diagnosed neuropathy (n = 42, 21 female, 21 male; 55.7 $\pm$ 15.7 years) and a healthy volunteer cohort (n = 10, 4 female, 6 male; 25.0 $\pm$ 2.6 years). Each MRN case consisted of a low-resolution T2-weighted image with fat suppression using inversion recovery (IR), and a high-resolution T2-weighted image without fat suppression (T2). Furthermore, three ground truth segmentations of the sciatic nerve, manually delineated by experts, were available per MRN case.
First, we trained a 2-D fully-convolutional neural network on the IR and T2 images separately, and on both combined, to investigate their impact on the segmentation performance.
Second, we developed and trained fully-convolutional neural networks with varying access to the 3-D context of the MRN images, and studied the impact of the 3-D context on the performance. Additionally, we investigated the potential use of a novel, projection-based loss function to incorporate a tubular-like shape prior into the neural network. 
Third, we applied post-processing to reduce the false positive rate in the segmentation of the neural networks. 
Last, we compared the performance of our best performing method to the human inter-rater variability obtained from the three manual ground truth segmentations.

Training a neural network only on the T2 image achieved almost the same performance as when trained on both (IR and T2) images. However, training on both images yielded reduced false positive segmentations as the IR image seems to help to distinguish between sciatic nerve and blood vessels.
Access to 3-D context allowed for better segmentation performance. However, given the properties of our MRN images (4.40 mm slice distance, the most proximal and distal slices contain peripheral nerve), we obtained the best results with a mainly 2-D driven approach with some 3-D context. Training with the proposed projection-based loss function resulted in slightly lower performance. But we think this loss function could be potentially useful for the incorporation of, e.g., anatomical shape priors during the training phase.
Applying our post-processing allowed for a better segmentation performance, especially with regard to the distance-based metrics as the 95\textsuperscript{th} percentile Hausdorff distance.
The best performing method achieved Dice coefficients of $0.779 \pm 0.123$ and $0.894 \pm 0.042$, volumetric similarities of $0.905 \pm 0.117$ and $0.942 \pm 0.050$, and 95\textsuperscript{th} percentile Hausdorff distances of $6.688  \pm 10.332$ mm and $0.655  \pm 0.355$ mm, for the patient and volunteer cohorts, respectively.
From a statistical and quantitative point of view, our method achieves, or in the case of the Dice coefficient for the volunteer cohort surpasses, human-level segmentation performances. Moreover, our method comes with significant time gains compared to manual segmentation, as the segmentation of an MRN case only takes around two minutes.

\end{abstract}
\endinput