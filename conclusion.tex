\chapter{Discussion and Conclusions} \label{chap:discussion_and_conclusions}
This chapter provides a discussion on the obtained results in Section~\ref{disc:discussion}. After the discussion, a conclusion on the outcome of this thesis is given in Section~\ref{disc:conclusions}.

\section{Discussion} \label{disc:discussion}
\subsection{Feasibility of Deep Learning for Peripheral Nerve Segmentation}
We successfully trained the baseline architecture on the \gls{mrn} images, achieving better results than reported in Balsiger et al. \cite{Balsiger2016DevelopmentApproaches} with the \gls{rf}-based approach. The results are in accordance with their recent deep learning-based approach~\cite{Balsiger2018SegmentationApproach}. Therefore, a deep learning-based approach for the peripheral nerve segmentation is feasible.
Comparing the results between the cohorts shows that our baseline performed better on the volunteer cohort. We suspect that the main reason for this discrepancy is the higher variability in the clinically acquired patient images. While the \gls{mrn} images for the volunteers were all taken from the same anatomical location, the images of the patients originate from variable locations between the distal thigh up to the head of the femur. An investigation of the segmentations shows a high prevalence of false positive outliers and occasionally false negatives, visible as slice-wise gaps along the nerve course. Outliers were often segmented where blood vessels are present in the \gls{mrn} images, whereas the slice-wise gaps seem to be an inherent artifact of the \gls{2d} approach.\\
The patient \gls{mrn} images tend to have more movement artifacts compared to the volunteer \gls{mrn} images. These artefacts make the image registration during the pre-processing more complex. To investigate a potential influence of the registration, we trained the baseline architecture on each of the \gls{mrn} images separately. Using only the T2 images, we were able to perform almost as good as when trained with both images (IR and T2). However, using only the IR images resulted in a worse \acrlong{dice} and a higher \acrlong{hd95}. It seems that the neural network was not able to learn the same quality of features and therefore to extract the same amount of information out of the IR images. We assume that a reason for the worse results might be that the unprocessed IR images have a lower in-plane resolution and are interpolated during the pre-processing. Furthermore, we suspect that the registration might be another issue: A subject-level investigation showed that there are cases where the registration is of low quality, hence there is misalignment between the IR and T2 images. Consequently, the IR images are also misaligned to the ground truths because the physicians used the T2 images for their manual ground truth segmentation. Such a misalignment is especially relevant for small structures as peripheral nerves. The misalignment might make it more complicated for the neural network to learn useful features from the IR images than from the T2 images. Interestingly, the IR image is useful for the segmentation in regards to the \gls{hd95} metric. The combination of the T2 and IR image for training resulted in a reduction of approximately 5 and 70 \% for the \acrlong{hd95} for the patient and volunteer cohort compared to the T2 image only for training. This reduction of the \gls{hd95} means that the IR image helps to reduce false positive outliers, especially in case of the volunteer cohort. An investigation of the subjects reveals that often blood vessels get segmented as nerves in the case of T2 only, probably due to their similar appearance to peripheral nerves on this \gls{mrn} sequence (cf. Figure~\ref{fig:subfig:T2}). The IR image, therefore, seems to help the network distinguish the nerve from blood vessels and other neighboring tissue. These findings align with the thinking pattern of physicians and the choice of the MRN sequences at the Inselspital: the T2 image is used for the coarse localization of the nerves and the IR image for the finer analysis due to the slightly hyper-intense appearance of nerves compared to the mostly surrounding tissue and blood vessels.

\subsection{Tailored 3-D Information for Peripheral Nerve Segmentation}
We successfully trained and evaluated the proposed neural networks with different degrees of access to \gls{3d} information. The stack-based method achieved almost constantly better results than the \gls{2d} baseline. The projection-based and patch-based methods resulted in worse performance. Our best performing method, stack-based 5-to-1, is on par or outperforms the method proposed by Balsiger et al.~\cite{Balsiger2018SegmentationApproach} with respect to the \acrlong{dice} and \acrlong{hd95}, achieving only slightly worse results concerning the \acrlong{vs}. Our mean and \gls{sd} of the \gls{hd95} of 1.5 $\pm$ 1.8 mm for the volunteer cohort are significantly lower than the \gls{hd95} of 13.9 $\pm$ 26.6 mm they reported.\\
The gain in performance with \gls{3d} information is, in general, higher for the patient cohort. This is mainly due to the reason that the \gls{2d} baseline architecture is already achieving good segmentation performance for the volunteer cohort and that there is not much space to improve. We still observe some false positive outliers in the segmentation results of the \gls{3d} architectures, however in reduced numbers. Furthermore, the false negative gaps are less frequent. In general, the stack-wise architectures can detect and segment the sciatic nerve in some cases where the baseline architecture failed.\\
We consistently achieved the best results concerning \acrlong{dice} and \acrlong{vs}, with the stack-based 5-to-1 architecture for both cohorts. Regarding the distance-metrics, the stack-based 3-to-1 and stack-based 5-to-3 performed the best for patient and volunteer cohort, respectively. However, seen overall metrics, the stack-based 5-to-1 neural network is performing the most robust. The architecture seems adequate and well suited for the task at hand for the intrinsic parameters (high in-plane resolution, large z-spacing) of our \gls{mrn} images.\\
Both stack-based 5-to-3 architectures (Stack\_5to3 and Stack\_Proj) did perform worse compared to the other \gls{3d} architectures, especially on the patient cohort. Therefore, for the segmentation of our \gls{mrn} images, predicting multiple slices at once with our configuration does not bring any benefit. Performance could potentially be increased, by reducing the axial stride from three down to one, resulting in each slice being predicted three times. The predictions could then be averaged for the segmentation.
Training the stack-based 5-to-3 architecture with the projection loss resulted in almost the same performances as the same architecture with the regular loss function, except for the \acrlong{avd}, which was nearly twice as large, in case of the volunteer cohort. An investigation of the volunteer \gls{mrn} cases revealed that there are more false positive outliers present in the segmentations of the projection-based loss.\\
The patch-based network performed the worst with regards to all metrics, even when compared to the baseline architecture. Despite having access to the \gls{3d} information of 12 consecutive slices, the reduction of the accessible in-plane information seems to restrict the neural network drastically in its segmentation capabilities. This emphasizes the importance of the in-plane context. However, we suspect a problem of our patch-based approach might be the fact that we use \textit{same}-padding and predict the same dimensions as the input. We think that \textit{valid}-padding and consequently predicting a smaller region might produce better results due to the network's receptive field.\\
Analyzing the heatmap of the achieved \gls{dice}s in Figure~\ref{fig:results_heatmap_dice}, three things become evident: First, all architectures perform better on the volunteer cohort. We already observed this in the previous experiment, and \gls{3d} context does not change this result. Second, the subjects where low performances were achieved, predominantly patients, are generally the same for all architectures. Hence, there are subjects which are inherently hard for all architectures to segment with high accuracy. Third, most of these subjects are patient subjects which have been examined and enrolled in an earlier stage in the registry. In some of these subjects, patient movement artifacts are noticeable. This suggests that the \gls{mrn} imaging protocol in the earlier stages was not optimal, and then subsequently got adjusted. Assessment of these subjects in the form of an outlier-analysis could be advisable.\\
In summary, we found that introducing \gls{3d} information can increase the performances to a certain extent. We also found that architectural changes as the number of features and number of input slices play a secondary role. More important is the general architecture, which has to adequate for the problem and the given data: in our case, a good mix between \gls{2d} and \gls{3d} convolutions, with a more dominant \gls{2d} part was the solution. This, given the intrinsic properties of our \gls{mrn} images, intuitively makes sense and is also in accordance with the results of Baumgartner et al.~\cite{Baumgartner2017AnSegmentation}. We, therefore, conclude that \gls{3d} context allows for better segmentation performance, given the right circumstances.

\subsection{Post-processing for Peripheral Nerve Segmentation}
We successfully applied our post-processing to the outputs of the baseline and stack-based 5-to-1 architectures. For both cohorts, joining the volumes and subsequently removing of all but the largest volumes (\textit{joint volumes} post-processing) yields the best segmentation performances with regard to all metrics. The single exception is the patient \acrlong{vs} of the baseline architecture, where no post-processing results in a higher \gls{vs}.\\
The post-processing was mainly motivated by the false positive segmentations. Therefore, the impact of post-processing on the distance metrics \gls{avd}, \gls{hd95} and \gls{hd} is far more dominant than on the overlap-based metrics, i.e., \gls{dice} and \gls{vs}. Inspection of the segmentation reveals that most of the false positive outliers can be removed by our post-processing, resulting in the significant better results for the distance metrics.
Concerning the \acrlong{hd95}, our post-processing benefits the stack-based 5-to-1 architecture even more than the baseline: the \gls{hd95} is reduced by approximately 45 \% for the stack-based approach, and reduced by about 25 \% for the baseline.\\
A limitation of our post-processing method is the calculation of the cheapest path for the volume connection: we only consider one path (the cheapest of all paths). This is applicable and fine for the cases that do not include the branching of the sciatic nerve. For the cases that include the branching, a better way would be to calculate two paths: both would start proximally in the sciatic nerve, and then after the branching follow the tibial and fibular nerve, respectively.
Furthermore, calculating the cheapest paths corresponds to find the centerline of the nerves. Centerlines have been found be useful for e.g. in blood vessels segmentation~\cite{Lesage2009ASchemes} and could be used for further refinement. We could extend the post-processing to result in an additional map that contains the pixels belonging to the cheapest paths and therefore designating the centerlines of the nerves.\\
Alternatively, perhaps more sophisticated methods of post-processing, similar to~\cite{Rempfler2015ReconstructingProgramming} and~\cite{Selvan2018ExtractionNetworks} could be applied to increase and solidify the segmentation performance even further. 

\subsection{Comparison to Human Inter-Rater Performance}
We took our best-performing architecture (stack-based 5-to-1) and compared the post-processed (\textit{joint volumes}) segmentation results to the human inter-rater performance. Our inter-rater study reveals that we achieve, or in the case of the \acrlong{dice} for the volunteer cohort even surpass, human-level segmentation performances from a quantitative and statistical point of view.\\
Looking at inter-rater agreement values for the metrics in Figure~\ref{fig:res_inter_rater} reveals that sciatic nerve segmentation is and remains a challenging task even for experts, and requires years of experience (agreement of OS to GT compared to the less experienced LG and BW). This puts the results of our method more into perspective and shows how, in fact, impressive the achieved segmentation performances are.\\
Comparing the time required for our fully-automatic method with the time required for an expert to manually segment a \gls{mrn} image, we see that our method results in a significant time gain for sciatic nerve segmentation.\\


\section{Conclusions} \label{disc:conclusions}
In our first experiment, we showed the feasibility of a deep learning-based approach for the segmentation of the sciatic nerve. Moreover, we showed training only on the T2 image was almost able to achieve the same results as when both images are used. Still, the neural network is able to extract useful information from the IR image. Therefore, training on both \gls{mrn} images is advisable.\\
We demonstrated in our second experiment that \gls{3d} context is indeed allowing for better segmentation performances. The amount of useful \gls{3d} context, however, heavily depends on the task at hand and the nature of the data. For our \gls{mrn} images, which have a high in-plane resolution, a large slice spacing, and a low axial resolution, a stack-wise architecture that allows for a tailored amount of \gls{3d} context achieved the best results.\\
With the use of post-processing, we showed that segmentations of the neural networks could be enhanced. While the impact of post-processing on the overlap-based metrics was rather small, the distance-metrics profited a lot.\\
The segmentation of the sciatic nerve, or peripheral nerves in general, from \gls{mrn} images remains a challenging but possibly important task. The segmentation could help clinicians in the diagnosis and monitoring of peripheral neuropathies, and could be used to calculate potentially useful image-derived biomarkers such as the \gls{fnr} and the \gls{csa}. A fast, robust and fully-automatic segmentation method is therefore desirable and beneficial. Finally, we showed in comparison with the inter-rater performance, that our method achieves or surpasses human-level segmentation performance concerning all metrics. Furthermore, our method requires significantly less time for the segmentation than manual segmentation.

\endinput