\chapter{Discussion and Conclusions} \label{chap:discussion_and_conclusions}
This chapter provides a discussion on the obtained results in Section~\ref{disc:discussion}. After the discussion, a conclusion on the outcome of this thesis is given in Section~\ref{disc:conclusions}.

\section{Discussion} \label{disc:discussion}
\subsection{Experiment 1: Feasibility}
We successfully trained the baseline architecture on the \gls{mrn} images, achieving better results than reported in Balsiger et al. \cite{Balsiger2016DevelopmentApproaches} with the \gls{rf}-based approach. The results are in accordance with their recent deep learning-based approach~\cite{Balsiger2018SegmentationApproach}. Therefore, a deep learning-based approach for the peripheral nerve segmentation is feasible.
Comparing the results between the cohorts, makes it evident that our baseline performed better on the volunteer cohort. We suspect that the main reason for this discrepancy is the higher variability in the clinically acquired patient images. While the \gls{mrn} images for the volunteers were all taken from the same anatomical location, the images of the patients originate from variable locations between the distal thigh up to the head of the femur. The patient \gls{mrn} images also tend to have more movement artefacts, which makes the registration during pre-processing more complex. To investigate a potential influcene of the registration, we trained the baseline architecture on each of the \gls{mrn} images separately. Using only the T2 images, we were able to perform almost as good as when trained with both images (IR and T2). However, using only the IR images resulted in a worse \acrlong{dice} and a higher \acrlong{hd95}. It seems that the neural network was not able to learn the same quality of features and therefore to extract the same amount of information out of the IR images. We assume that the main reason for this is that the unprocessed IR images have a lower in-plane resolution and are interpolated during the pre-processing. Furthermore, we suspect that the registration may be another issue: A subject-level investigation showed that there are cases where the registration is of low quality, hence there is misalignment between the IR and T2 images. Consequently, the IR images are also misaligned to the ground truths because the physicians used the T2 images for their manual ground truth segmentation. This might make it more complicated for the neural network to learn useful features for the IR images than for the T2 images. Interestingly, the IR image is useful for the segmentation in regards of the \gls{hd95} metric.

\subsection{Experiment 2: 3D context}
\subsection{Experiment 3: Post-processing}
\subsection{Evaluation}
\section{Conclusions} \label{disc:conclusions}

\endinput