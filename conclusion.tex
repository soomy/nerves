\chapter{Discussion and Conclusions} \label{chap:discussion_and_conclusions}
This chapter provides a discussion on the obtained results in Section~\ref{disc:discussion}. After the discussion, a conclusion on the outcome of this thesis is given in Section~\ref{disc:conclusions}.

\section{Discussion} \label{disc:discussion}
\subsection{Experiment 1: Feasibility}
We successfully trained the baseline architecture on the \gls{mrn} images, achieving better results than reported in Balsiger et al. \cite{Balsiger2016DevelopmentApproaches} with the \gls{rf}-based approach. The results are in accordance with their recent deep learning-based approach~\cite{Balsiger2018SegmentationApproach}. Therefore, a deep learning-based approach for the peripheral nerve segmentation is feasible. 
Comparing the results between the cohorts makes it evident that our baseline performed better on the volunteer cohort. We suspect that the main reason for this discrepancy is the higher variability in the clinically acquired patient images. While the \gls{mrn} images for the volunteers were all taken from the same anatomical location, the images of the patients originate from variable locations between the distal thigh up to the head of the femur. The patient \gls{mrn} images also tend to have more movement artifacts, which makes the registration during pre-processing more complex.\\
An investigation of the segmentations shows a high prevalence of false positive outliers and occasionally false negatives, visible as slice-wise gaps. Outliers are often segmented where blood vessels are present in the \gls{mrn} images, whereas the slice-wise gaps seem to be an inherent artifact of the \gls{2d} approach.\\
To investigate a potential influence of the registration, we trained the baseline architecture on each of the \gls{mrn} images separately. Using only the T2 images, we were able to perform almost as good as when trained with both images (IR and T2). However, using only the IR images resulted in a worse \acrlong{dice} and a higher \acrlong{hd95}. It seems that the neural network was not able to learn the same quality of features and therefore to extract the same amount of information out of the IR images. We assume that the main reason for this is that the unprocessed IR images have a lower in-plane resolution and are interpolated during the pre-processing.
Furthermore, we suspect that the registration may be another issue: A subject-level investigation showed that there are cases where the registration is of low quality, hence there is misalignment between the IR and T2 images. Consequently, the IR images are also misaligned to the ground truths because the physicians used the T2 images for their manual ground truth segmentation. This might make it more complicated for the neural network to learn useful features for the IR images than for the T2 images. Interestingly, the IR image is useful for the segmentation in regards to the \gls{hd95} metric: training on both images resulted in a reduction of approximately 5 and 70 \% for the \acrlong{hd95} for the patient and volunteer cohort, respectively. This reduction for the \gls{hd95} metric means that the IR image helps to reduce false positive outliers, especially in case of the volunteer cohort. An investigation of the subjects reveals that often blood vessels get segmented as nerves. This is probably due to their similar appearance in the T2 images, which can be seen in the T2 Image~\ref{fig:subfig:T2} in the Chapter~\ref{sec:materials}. The IR image, therefore, seems to help the network distinguish the nerve from and blood vessels and neighboring tissue. These findings align with the thinking pattern of physicians and the choice of the MRN sequences at our institution: the T2 image is used for the coarse localization of the nerves and the IR image for the finer analysis due to the slightly hyper-intense appearance of nerves compared to the mostly surrounding tissue and blood vessels.

\subsection{Experiment 2: 3D context}
We successfully trained and evaluated the proposed neural networks with different degrees of access to  \gls{3d} information. The stack-based method achieved almost constantly better results than the baseline. The projection-based and patch-based methods resulted in worse performance. Our best performing method, stack-based 5-to-1, outperforms the method proposed by Balsiger et al.~\cite{Balsiger2018SegmentationApproach} with respect to the \acrlong{dice} and \acrlong{hd95}, achieving only slightly worse results concerning the \acrlong{vs}.\\
The gain in performance with \gls{3d} information is, in general, higher for the patient cohort. This is mainly due to the reason that the \gls{2d} baseline architecture is already achieving good segmentation performance for the volunteer cohort and that there is not much space to improve. We still observe some false positive outliers in the segmentation results of the \gls{3d} architectures, however in reduced numbers. Furthermore, the gaps are less frequent. In general, the stack-wise architectures can detect and segment the sciatic nerve in some cases where the baseline architecture failed.\\
We consistently achieved the best results concerning the \acrlong{dice} and \acrlong{vs}, with the stack-based 5-to-1 architecture for both cohorts. Regarding the distance-metrics, the stack-based 3-to-1 and stack-based 5-to-3 performed the best for patient and volunteer cohort, respectively. However, seen overall metrics, the stack-based 5-to-1 neural network is performing the most robust. The architecture seems adequate and well suited for the task at hand for the intrinsic parameters (high in-plane resolution, large z-spacing) of our \gls{mrn} images.\\
Both stack-based 5-to-3 architectures (Stack\_5to3 and Stack\_Proj) did perform worse, especially on the patient cohort. Therefore, for the segmentation of our \gls{mrn} images, predicting multiple slices at once does not bring any benefit. Performance could potentially be increased, by reducing the axial stride from three down to one, resulting in each slice being predicted three times. The predictions could then be averaged for the segmentation.
Training the stack-based 5-to-3 architecture with the projection loss resulted in almost the same performances as the same architecture with the regular loss function, except for the \acrlong{avd}, which was nearly twice as large, in case of the volunteer cohort. An investigation of the volunteer \gls{mrn} cases revealed that there are more false positive outliers present in the segmentations of the projection-based loss.\\
The patch-based network performed the worst with regards to all metrics, even when compared to the baseline architecture. Despite having access to the \gls{3d} information of 12 consecutive slices, the reduction of the accessible in-plane information seems to restrict the neural network drastically in its segmentation capabilities. This emphasizes the importance of the \gls{2d} context and speaks for robust and global \gls{2d} features. However, we suspect a problem our patch-based approach may be the fact that we do \textit{same}-padding and predict the same dimensions as the input. We think that \textit{valid}-padding and consequently predicting a smaller region should produce better results.\\
As a consequence of the intrinsics of our \gls{mrn} images, information which helps a robust segmentation is mostly available and extracted from the \gls{2d} context, hence from the individual slices of a \gls{mrn} image. This allows for already remarkable and quite robust segmentation performances of a simple, \gls{2d} based neural network as the baseline. However, we found that introducing some \gls{3d} convolutional layers can increase the performances to a certain extent. \\
Furthermore, we found that architectural changes as the number of features and number of input slices play a secondary role. More important is the general architecture, which has to adequate for the problem and the given data: in our case, a good mix between \gls{2d} and \gls{3d} convolutions, and a more \gls{2d} dominantly driven approach was the solution. This, given the intrinsic parameters of our \gls{mrn} images, intuitively makes sense and is also in accordance with the results of Baumgartner et al.~\cite{Baumgartner2017AnSegmentation}.\\
We, therefore, conclude, that \gls{3d} context allows for better segmentation performance, given the right circumstances.


-Fälle welche sehr schwierig sind:
-->Vermeht patients, Früh im Zeitpunkt der Aufnahme
-->Evtl zu schlechte qualität --> Outlier analyse von oli evtl notwendig




\subsection{Experiment 3: Post-processing}
- Bringts generell
- Unterschiedlich für die metriken Overlap vs Distance
- 2D und 3d profitieren unteschiedlich
- Problem mit branching
- 1 stunde zum bererchenn
-Centerline ist toll


\subsection{Comparison to Human Inter-Rater Performance}
- Oli ist der beste rater da er am meisten CGT übereinstimmt


\section{Conclusions} \label{disc:conclusions}


Although not used in this work, further MRN images from different anatomical regions (upper \& lower arm, lower leg) are available for the volunteer cohort. The upper leg \gls{mrn} images of the six healthy volunteers which Balsiger et al.~\cite{Balsiger2016DevelopmentApproaches} used for their work, are also part of the dataset.\\

\endinput