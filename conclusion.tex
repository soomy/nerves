\chapter{Discussion and Conclusions} \label{chap:discussion_and_conclusions}
This chapter provides a discussion on the obtained results in Section~\ref{disc:discussion}. After the discussion, a conclusion on the outcome of this thesis is given in Section~\ref{disc:conclusions}.

\section{Discussion} \label{disc:discussion}
\subsection{Experiment 1: Feasibility}
We successfully trained the baseline architecture on the \gls{mrn} images, achieving better results than reported in Balsiger et al. \cite{Balsiger2016DevelopmentApproaches} with the \gls{rf}-based approach. The results are in accordance with their recent deep learning-based approach~\cite{Balsiger2018SegmentationApproach}. Therefore, a deep learning-based approach for the peripheral nerve segmentation is feasible.
Comparing the results between the cohorts makes it evident that our baseline performed better on the volunteer cohort. We suspect that the main reason for this discrepancy is the higher variability in the clinically acquired patient images. While the \gls{mrn} images for the volunteers were all taken from the same anatomical location, the images of the patients originate from variable locations between the distal thigh up to the head of the femur. The patient \gls{mrn} images also tend to have more movement artifacts, which makes the registration during pre-processing more complex.\\
An investigation of the segmentations shows a high prevalence of false positive outliers and occasionally false negatives, visible as slice-wise gaps. Outliers are often segmented where blood vessels are present in the \gls{mrn} images, whereas the slice-wise gaps seem to be an inherent artifact of the \gls{2d} approach.\\
To investigate a potential influence of the registration, we trained the baseline architecture on each of the \gls{mrn} images separately. Using only the T2 images, we were able to perform almost as good as when trained with both images (IR and T2). However, using only the IR images resulted in a worse \acrlong{dice} and a higher \acrlong{hd95}. It seems that the neural network was not able to learn the same quality of features and therefore to extract the same amount of information out of the IR images. We assume that the main reason for this is that the unprocessed IR images have a lower in-plane resolution and are interpolated during the pre-processing.
Furthermore, we suspect that the registration may be another issue: A subject-level investigation showed that there are cases where the registration is of low quality, hence there is misalignment between the IR and T2 images. Consequently, the IR images are also misaligned to the ground truths because the physicians used the T2 images for their manual ground truth segmentation. This might make it more complicated for the neural network to learn useful features for the IR images than for the T2 images. Interestingly, the IR image is useful for the segmentation in regards to the \gls{hd95} metric: training on both images resulted in a reduction of approximately 5 and 70 \% for the \acrlong{hd95} for the patient and volunteer cohort, respectively. This reduction for the \gls{hd95} metric means that the IR image helps to reduce false positive outliers, especially in case of the volunteer cohort. An investigation of the subjects reveals that often blood vessels get segmented as nerves. This is probably due to their similar appearance in the T2 images, which can be seen in the T2 Image~\ref{fig:subfig:T2} in the Chapter~\ref{sec:materials}. The IR image, therefore, seems to help the network distinguish the nerve from and blood vessels and neighboring tissue. These findings align with the thinking pattern of physicians and the choice of the MRN sequences at our institution: the T2 image is used for the coarse localization of the nerves and the IR image for the finer analysis due to the slightly hyper-intense appearance of nerves compared to the mostly surrounding tissue and blood vessels.

\subsection{Experiment 2: 3D context}
We successfully trained and evaluated the proposed neural networks with different degrees of access to  \gls{3d} information. The stack-based method achieved almost constantly better results than the baseline. The projection-based and patch-based methods resulted in worse performance. Our best performing method, stack-based 5-to-1, is on par or outperforms the method proposed by Balsiger et al.~\cite{Balsiger2018SegmentationApproach} with respect to the \acrlong{dice} and \acrlong{hd95}, achieving only slightly worse results concerning the \acrlong{vs}. Our mean and \gls{sd} for the \gls{hd95} of 1.5 $\pm$ 1.8 mm for the volunteer cohort is significantly lower than the \gls{hd95} of 13.9 $\pm$ 26.6 mm they reported\\
The gain in performance with \gls{3d} information is, in general, higher for the patient cohort. This is mainly due to the reason that the \gls{2d} baseline architecture is already achieving good segmentation performance for the volunteer cohort and that there is not much space to improve. We still observe some false positive outliers in the segmentation results of the \gls{3d} architectures, however in reduced numbers. Furthermore, the gaps are less frequent. In general, the stack-wise architectures can detect and segment the sciatic nerve in some cases where the baseline architecture failed.\\
We consistently achieved the best results concerning the \acrlong{dice} and \acrlong{vs}, with the stack-based 5-to-1 architecture for both cohorts. Regarding the distance-metrics, the stack-based 3-to-1 and stack-based 5-to-3 performed the best for patient and volunteer cohort, respectively. However, seen overall metrics, the stack-based 5-to-1 neural network is performing the most robust. The architecture seems adequate and well suited for the task at hand for the intrinsic parameters (high in-plane resolution, large z-spacing) of our \gls{mrn} images.\\
Both stack-based 5-to-3 architectures (Stack\_5to3 and Stack\_Proj) did perform worse, especially on the patient cohort. Therefore, for the segmentation of our \gls{mrn} images, predicting multiple slices at once does not bring any benefit. Performance could potentially be increased, by reducing the axial stride from three down to one, resulting in each slice being predicted three times. The predictions could then be averaged for the segmentation.
Training the stack-based 5-to-3 architecture with the projection loss resulted in almost the same performances as the same architecture with the regular loss function, except for the \acrlong{avd}, which was nearly twice as large, in case of the volunteer cohort. An investigation of the volunteer \gls{mrn} cases revealed that there are more false positive outliers present in the segmentations of the projection-based loss.\\
The patch-based network performed the worst with regards to all metrics, even when compared to the baseline architecture. Despite having access to the \gls{3d} information of 12 consecutive slices, the reduction of the accessible in-plane information seems to restrict the neural network drastically in its segmentation capabilities. This emphasizes the importance of the \gls{2d} context and speaks for robust and global \gls{2d} features. However, we suspect a problem our patch-based approach may be the fact that we do \textit{same}-padding and predict the same dimensions as the input. We think that \textit{valid}-padding and consequently predicting a smaller region should produce better results.\\
Looking at the heatmap of the achieved \gls{dice} in Figure~\ref{fig:results_heatmap_dice}, three things become evident: first, all the architectures perform better on the volunteer cohort. We already observed this in the previous experiment, and \gls{3d} context does not change this. Second, the subjects where low performances are achieved, predominantly patients, are generally the same for all architectures. Hence, there are subjects which are inherently hard for all architectures to segment with high accuracy. Third, most of these subjects are patient subjects which have been examined and enrolled in an earlier stage in the registry. In some of these subjects, patient movement artifacts are noticeable. This could mean that the \gls{mrn} imaging protocol in the earlier stages was not optimal, and then subsequently got adjusted. Assessment of these subjects in the form of an outlier-analysis could be advisable.\\
As a consequence of the intrinsics of our \gls{mrn} images, information which helps a robust segmentation is mostly available and extracted from the \gls{2d} context, hence from the individual slices of a \gls{mrn} image. This allows for already remarkable and quite robust segmentation performances of a simple, \gls{2d} based neural network as the baseline. However, we found that introducing some \gls{3d} convolutional layers can increase the performances to a certain extent. \\
Furthermore, we found that architectural changes as the number of features and number of input slices play a secondary role. More important is the general architecture, which has to adequate for the problem and the given data: in our case, a good mix between \gls{2d} and \gls{3d} convolutions, and a more \gls{2d} dominantly driven approach was the solution. This, given the intrinsic parameters of our \gls{mrn} images, intuitively makes sense and is also in accordance with the results of Baumgartner et al.~\cite{Baumgartner2017AnSegmentation}.\\
We, therefore, conclude, that \gls{3d} context allows for better segmentation performance, given the right circumstances.

\subsection{Experiment 3: Post-processing}
We successfully applied our different degrees of post-processing to the outputs of the baseline and stack-based 5-to-1 architectures. For both cohorts, joining the volumes and subsequently removing of all but the largest volumes (referred to as \textit{joint volumes} post-processing) yields the best segmentation performances with regard to all metrics. The single exception is the patient \acrlong{vs} of the baseline architecture, where no post-processing results in a higher value.\\
The impact of post-processing on the distance metrics \gls{avd}, \gls{hd95} and \gls{hd} is far more dominant than on the overlap-based metrics, i.e., \gls{dice} and \gls{vs}. Inspection of the segmentation reveals that most of the false positive outliers can be removed by our post-processing, resulting in the significant drops of the distance metrics.\\
Concerning the \acrlong{hd95}, our post-processing benefits the stack-based 5-to-1 architecture even more than the baseline: the \gls{hd95} is reduced by approximately 45 \% for the stack-based approach, and reduced by about 25 \% for the baseline.
A limitation of our post-processing method is the calculation of the cheapest way for the volume connection: we only calculate one path (we only take the cheapest of all paths). This is applicable and fine for the cases which do not include the branching of the sciatic nerve. For the cases which include the branching, a better way would be to calculate two paths: both would start proximal in the sciatic nerve, and then after the branching follow the tibial and fibular nerve, respectively.
Furthermore, calculating the cheapest paths corresponds to find the centerline of the nerves. We could extend the post-processing to result in an additional map which containing the pixels belonging to the cheapest paths and therefore designating the centerlines of the nerves.

\subsection{Comparison to Human Inter-Rater Performance}
We took our best-performing architecture (stack-based 5-to-1) and compared the post-processed (\textit{joint volumes}) segmentation results to the human inter-rater performance. Our inter-rater study reveals that we achieve or even surpass human-level segmentation performances with respect to all metrics from a quantitative and statistical point of view.\\
Comparing the times required for a fully-automatic segmentation with our method with the time required for an expert to manually segment a \gls{mrn} image, we see that our method results in a significant time gain for sciatic nerve segmentation.\\
Looking at inter-rater agreement values for the metrics in Figure~\ref{fig:res_inter_rater} reveals that sciatic nerve segmentation is and remains a challenging task even for experts, and requires years of experience.

\section{Conclusions} \label{disc:conclusions}
We conclude this thesis with the following points:
In our first experiment, we showed the feasibility of a deep learning-based approach for the segmentation of the sciatic nerve. Moreover, we showed training only on the T2 image was almost able to achieve the same results as when both images are used. Still, the neural network is able to extract useful information from the IR image. Therefore, training on both \gls{mrn} images is advisable.\\
We demonstrated in our second experiment that \gls{3d} context is indeed allowing for better segmentation performances. The amount of useful \gls{3d} context, however, heavily depends on the task at hand and the nature of the data. For our \gls{mrn} images, which have high in-plane resolutions, a large slice spacing and a low axial resolution, a stack-wise architecture with allowing for some \gls{3d} context achieved the best results.\\
With the use of post-processing, we showed that segmentations of the neural networks could be enhanced. While the impact of post-processing on the overlap-based metrics was rather small, the distance-metrics profited a lot.\\
The segmentation of the sciatic nerve, or peripheral nerves in general, from \gls{mrn} images remains a challenging but important task. The segmentation can help clinicians in the diagnosis of peripheral neuropathies, and can be used to calculate potentially useful biomarkers as the \gls{fnr} and the \gls{csa}. A fast, robust and fully-automatic segmentation method is therefore desirable and beneficial. Finally, we showed in comparison with the inter-rater performance, that our method achieves or surpasses human-level segmentation performance concerning all metrics. Furthermore, our method requires significantly less time for the segmentation task.

\endinput