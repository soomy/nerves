\chapter{Introduction} % =================================================================================
Our nervous system is divided into two parts: The \gls{cns}, which consists of the brain and the spinal cord, and the \gls{pns} which includes all of the nerves that branch out from the brain and spinal cord into the most distal areas of our body. Peripheral neuropathies are common and can result in deficiencies or restrictions of sensory or motor abilities.\\
Diagnosis and assessment of peripheral neuropathies traditionally rely on neurological examinations which might provide inconclusive results, or are not amenable to deeply situated peripheral nerves. Recently the use of \gls{mri}, tailored to the peripheral nerves, called \acrlong{mrn} (\acrshort{mrn}) as a complementary diagnostic tool has gained popularity. A problem, however, is the fact that as of today \acrshort{mrn} is a qualitative examination as it is subjectively assessed by the radiologist. The use of \acrshort{mrn} images to extract potential quantitative biomarkers, such as cross-sectional area and nerve compartment volume ratio have been proposed~\cite{Kronlage2017,Felisaz2017MRNeuropathy.}. However, a prerequisite for calculation of such biomarkers is the segmentation of the \gls{pns}, which comes in with expensive and tedious work for radiologists.\\
For this reason, we aim to extract the nerves of the \gls{pns} automatically from \acrshort{mrn} images, using a deep learning-based approach. This introductory chapter starts with the medical motivation, including an anatomical overview of the \gls{pns}, a listing of peripheral neuropathies and the current state-of-the-art of diagnosis in Section~\ref{sec:intro_medical}. Section~\ref{sec:intro_mia} provides a short outline of medical image analysis and the segmentation problem. Section~\ref{sec:intro_mlearn} introduces some topics of machine learning. Finally, the chapter is concluded by the elaboration of our hypothesis, and the aim and structure of this thesis.

\section{Medical Motivation} \label{sec:intro_medical} % ===========================================================================
\subsection{Anatomy}
Our nervous system is divided into two parts: The \gls{cns}, including the brain and the spinal cord, and the \gls{pns} which comprises all of the nerves that branch out from the brain and spinal cord into the most distal areas of our body. In general, the \gls{pns} connects the \gls{cns} to all parts of the body. Both, the \gls{pns} and the \gls{cns} consist of efferent nerves which transmit signals from the brain to the effectors, i.e., muscles and glands, of the different body parts, and afferent nerves which transmit signals from the receptors to the brain. The \gls{pns} is split into the \gls{sns}, responsible for sensory input and motor output, and the \gls{ans} which controls involuntary responses to regulate physiological functions. Furthermore, the \gls{ans} divides into the sympathetic and the parasympathetic divisions, which act antagonistically: While the sympathetic division is responsible for "flight-or-fight" functions (e.g. increasing of heart-rate and lung action, inhibition of stomach and intestinal function), the parasympathetic division promotes the "rest-and-digest" functions (e.g. body relaxes, buildup of reserves) of the body.\\
Figure~\ref{fig:subfig:anat_spinal} depicts how the \gls{pns} is connected to the \gls{cns}: Nerve rootlets, which are groups of axons, form a spinal nerve. Nerve rootlets, leaving the spinal cord ventral, belong typically to motor nerves. Nerve rootlets belonging to sensory nerves typically enter the spinal cord dorsal.\\
Figure~\ref{fig:subfig:anat_nerve} shows the cable-like structure of peripheral nerves. Each nerve contains many axons, are also called nerve fibers, which are hierarchically bundled together. Groups of nerve fibers are surrounded by the first layer of connective tissue called endoneurium. Multiple groups of surrounded nerve fibers bundled together, and surrounded by another layer of connective tissue called perineurium, form a fascicle. Multiple fascicles, but also blood vessels, surrounded by a final layer of connective tissue called epineurium, form a peripheral nerve. The blood vessels supply the nutrients. The nerves fibers can be myelinated or unmyelinated. Myelination acts as an insulator and increases the transmission velocity of neura signals.\\
Figures~\ref{fig:subfig:anat_sagittal} and \ref{fig:anat_axial} show the main nerves of the \gls{pns} of the lower limb, and a cross-sectional view of the right upper leg including the \gls{n.} ischiadicus. We chose to depict the nerves of the lower limb only. Our \acrshort{mrn} images we work with, are all taken from the anatomical region of the thigh and, therefore, include parts of \gls{n.} ischiadicus, and typically the branching where it splits into \gls{n.} tibials and \gls{n.} fibularis, proximal to the knee. This is mentioned in detail in Section~\ref{sec:materials} of Chapter~\ref{chap:methods}. After this chapter we will refer to \gls{n.} ischiadicus by its english name \textit{sciatic nerve}.

\begin{figure}[htbp]
    \begin{minipage}[c][0.9\textheight][t]{.5\textwidth}
        \centering
        \vspace*{\fill}
        \subfloat[]
        {
            \includegraphics[width=\linewidth]{anat_sagittal}
            \label{fig:subfig:anat_sagittal}
        }
    \end{minipage}
    \begin{minipage}[c][0.9\textheight][t]{.5\textwidth}
        \centering
        \vspace*{\fill}
        \subfloat[]
        {
            \includegraphics[width=\linewidth]{anat_spinal}
            \label{fig:subfig:anat_spinal}
        }
        \vfill
        \subfloat[]
        {
            \includegraphics[width=\linewidth]{anat_nerve}
            \label{fig:subfig:anat_nerve}
        }
    \end{minipage}
    \vspace*{-0.3cm}
    \caption[Anatomy of the Peripheral Nervous System]{The anatomy of the \gls{pns} on different scales. \textbf{(a)} Nerves of the \gls{pns} of the lower limb, including \gls{n.} ischiadicus. \gls{n.} ischiadicus splits into \gls{n.} tibialis and \gls{n.} fibularis proximal to the knee. Image from~\cite{Schunke2014PrometheusAnatomie}. \textbf{(b)} Sensory nerves entering the spinal cord dorsal, motor nerves exiting the spinal cord ventral. Image from~\cite{Schunke2015THIEMEAnatomy} \textbf{(c)} Structure of a peripheral nerve. Image from~\cite{Schunke2015THIEMEAnatomy}.}
    \label{fig:anat}
\end{figure}

\begin{figure}[htbp]
	\includegraphics[width=\textwidth]{anat_axial}
    \caption[Cross-section of the Right Upper Leg]{Cross-sectional view of the right upper leg with femur, muscles, blood vessels and \gls{n.} ischiadicus. Image from~\cite{Schunke2014PrometheusAnatomie}.}
    \label{fig:anat_axial}
\end{figure}

\subsection{Peripheral Neuropathies}
The prevalence of peripheral neuropathies is approximatively 2.4 \% and rising to 8.0 \% with the age $\geq$ 55 years \cite{Martyn1997EpidemiologyNeuropathy}. The most common cause of peripheral neuropathies in the developed world is diabetes mellitus. Other causes include metabolic disorders, infections, toxins, and drugs \cite{England2004PeripheralNeuropathy,Hughes466}.
Peripheral neuropathies can be caused by the damage of the axons or by demyelination which hinders the fast transmission of neural signals. 
As the \gls{ans} controls almost every organ, a wide range of symptoms can arise when it is damaged. Damage to motor nerves may give rise to movement impairment or muscle weakness~\cite{Mohassel2015}. Damage to sensory nerves can be the cause of pain or altered sensation.

\subsection{State-of-the-Art Diagnosis}
Biopsies, which are common in other medical fields, e.g., for the diagnosis or examinations of tumors and pathologies, are rarely conducted due to the irreversible damage to the nerves. \gls{eds} of the \gls{pns} are clinical tools that aid in the diagnostic assessment of patients with signs and symptoms of peripheral neuropathies~\cite{Mohassel2015}. \gls{eds} are used as an extension of the neurologic examination, and their primary goal is to help with localization of peripheral nerve lesions and find their distribution~\cite{Mohassel2015} (focal, multifocal, or generalized; one segment, multiple segments, or diffuse within the nerve). Additionally, \gls{eds} help determining age, severity, pathology, prognosis and can be used for treatment planning~\cite{Mohassel2015}. Many physiologic and non-physiologic factors, e.g., age, height, tissue temperature, and pathology influence \gls{eds}. Normally, \gls{eds} are composed of two different tests, which are related and complement each other.\\

\textbf{\gls{ncs}}: \gls{ncs} measure the electrical signal propagation along a given nerve. The nerve of interest is stimulated at one site, and the electrical response signal is measured at another and is analyzed. Correct stimulation of proximal and deeper nerves is difficult. Hence those nerves are typically hard to assess with \gls{ncs}~\cite{Mohassel2015}. Typical signal measurements for \gls{ncs} include distal latency, amplitude, conduction velocity, and late response latency. Prolonged distal and late response latency, and reduced conduction velocity can indicate degeneration of the myelin sheath. A decreased amplitude can be the indicator of axonal degeneration~\cite{Mohassel2015}.\\

\textbf{\gls{emg}}: \gls{emg} or needle {emg} complements \gls{ncs}, and can help confirm suspected pathologic processes. As \gls{emg} comes with discomfort for the patient, and a large number of muscles which could potentially be studied, it is important to have a detailed anatomical knowledge and a hypothesis-driven approach~\cite{Mohassel2015}. The \gls{emg} needle is an electrode that is directly inserted into the muscle and locally samples electrical activity of the muscle fibers. \gls{emg} includes evaluation of spontaneous activity at rest and the assessment of voluntary motor units upon activation~\cite{Mohassel2015}.\\
As of today \gls{eds} are the first choice for diagnosis of peripheral neuropathies. Apparent drawbacks are the insertion of the needle during \gls{emg} and that electrical stimulation may be painful or cause discomfort. Furthermore, \gls{eds} may not be applicable to nerves situated deep in the body or may yield inconclusive results.

\subsection{Imaging of the Peripheral Nervous System}
Imaging of the \gls{pns} as a complementary diagnostic tool to the state-of-the-art diagnosis has gained increasing attention in recent years. The following modalities are usually used to image the \gls{pns}~\cite{Ohana2014CurrentSystem}.\\

\textbf{\gls{us}}: As the nerves of the \gls{pns} usually are very superficial, \gls{us} can be used for examination. Figure~\ref{fig:subfig:imag_us} shows \gls{us} images of the \gls{n.} ulnaris. \gls{us} is cheap and widely available. Other advantages include the excellent spatial resolution, the large gls{fov}, and that there are no contraindications. \gls{us} however, is very operator dependent and also suffers from poor contrast resolution of for the nerves. Furthermore, there are limitations to the applicability of \gls{us} in deep or hardly accessible anatomical areas~\cite{Ohana2014CurrentSystem}.\\

\textbf{\gls{mrn}}: \gls{mrn} is \gls{mri} tailored to the monitoring of peripheral nerves. Optimized image sequences allow for better contrast between the nerves and their environment. Phased-array coils and high field imager increase signal-to-noise ratio as well as the spatial resolution, allowing the structure of the nerves to be examined. \gls{mrn} has excellent soft-tissue contrast and a higher \gls{fov} than \gls{us}. The resulting images are \gls{3d} and even deeply situated nerves can be imaged. Typically the \gls{mrn} protocols make use of T1-weighted spin-echo sequences (excellent spatial resolution), T2-weighted spin-echo sequences (good contrast resolution) and "neurography" sequences, which are highly T2-weighted using long echo times and fat signal suppression~\cite{Ohana2014CurrentSystem}. Advantages of \gls{mrn} include the excellent contrast and the outstanding spatial resolutions. \gls{mrn}, however, is rather costly, has limited availability and acquisition may take a long time. Figure~\ref{fig:subfig:imag_mrn} depicts \gls{mrn} images.\\

\textbf{\gls{ct}}: Despite not being used as often as the previous modalities, \gls{ct} has some benefits. \gls{ct} is useful in diagnosing spinal nerve compressions, has a good spatial resolution, excellent bone contrast and can be used to perform \gls{ct} angiography. The good spatial resolution allows the for diagnosis of peripheral nerve tumors. However, although large nerve trunks are often visible, the low contrast resolution does not allow a detailed examination in the neuronal microstructure~\cite{Ohana2014CurrentSystem}. Another disadvantage is the inherent irradiation of the tissue. Figure~\ref{fig:subfig:imag_ct} shows a curvilinear nerve reconstruction based on a \gls{ct} angiogram.\\


\begin{figure}[htbp]
	\centering
	\subfloat[]
	{
		\label{fig:subfig:imag_us}
		\includegraphics[width=0.48\textwidth]{imag_us}
	}
	\hfill
	\subfloat[]
	{
		\label{fig:subfig:imag_mrn}
		\includegraphics[width=0.48\textwidth]{imag_mrn}
	}
	\hfill
	\subfloat[]
	{
		\label{fig:subfig:imag_ct}
		\includegraphics[width=0.7\textwidth]{imag_ct}
	}
	\caption[Modalities for Imaging of the Peripheral Nervous System]{Different imaging modalities, which are used to image the \acrlong{pns}. Images from~\cite{Mohassel2015}. \textbf{(a)} \gls{n.} ulnaris, at the wrist, which is visible in axial and longitudinal ultrasound sections. \textbf{(b)} Sagittal sections of the \gls{n.} medianus: T1-weighted (top) and T2-weighted with fat suppression (bottom). \textbf{(c)} Curvilinear reconstructions of the right \gls{n.} ischiaducus from a lower limb CT angiogram.}
	\label{fig:imag_modalities}  
\end{figure}

\section{Medical Image Segmentation} \label{sec:intro_mia} % ===================================================================
Segmentation in digital image processing refers to the extraction of a target structure of interest from an image, or to partition the image into multiple segments which result in a representation which is easier to analyze. Typically object boundaries, or regions belonging to one semantic object are of interest. The task of segmentation, in essence, boils down to the pixel-wise assignment of class labels. Commonly pixels belonging to the same labels share some characteristics.\\
Medical image segmentation usually involves the segmentation of an anatomical object of interest in some medical image, e.g., \gls{ct} or \gls{mri}. Usually, the segmentation has to be done manually by an expert, is not always reproducible, means tedious work and is time-consuming. Even more so, by the fact that the results of image modalities as \gls{ct}, \gls{mri} or \gls{mrn} are \gls{3d} images. Automatic or semi-automatic, computer-assisted segmentation pipelines and tools exist but are not always able to deliver the required performance. Recently, deep learning-based segmentation of medical images, with the use of convolutional neural networks has become increasingly popular~\cite{Ronneberger2015U-Net:Segmentation,Tetteh2018DeepVesselNet:Volumes,Cicek20163DAnnotation,Baumgartner2017AnSegmentation,Meng2017TrackingNetwork,Milletari2016V-Net:Segmentation,BalsigerContext-awareNeurography,Kayalibay2017CNN-basedData}, and human-level performances have been achieved or even surpassed.

\section{Machine Learning} \label{sec:intro_mlearn} % =============================================================================
In this part we briefly describe some fundamentals of machine learning. Machine learning is a huge topic and this section is by no means meant to be a complete overview. We only rather introduce some concepts and mention topics which were related and important for our work.

\subsection{Supervised Learning} \label{sec:ml_supervised}
The principle of supervised learning is illustrated on the prediction of house prizes as a function of their living area in Figure~\ref{fig:dl_supervised} taken from~\cite{Ng2012StanfordNotes}. In supervised learning, we train an algorithm (or also called model) by showing the algorithm input-output pairs (e.g., living area of houses versus their corresponding prizes). This is referred to as the training phase, and the input-output pairs are called the training set. The outputs are typically referred to as labels or targets. More formally we define the training set as
\begin{equation}
   S_{Train} = \{(x^{(i)}, y^{(i)}); i = 1,...,m\}
   \label{eq:training_set}
\end{equation}
and let $\chi$ and $\upsilon$ denote the space of input and output values, respectively. In this example, $\chi = \upsilon = \mathbb{R}$. The aim of the training phase is to let the algorithm (hopefully) learn a meaningful relationship between the inputs and outputs of our training set. Therefore, we aim learn a mapping $h : \chi \mapsto \upsilon$, parameterized by a set of models weights~$\textbf{W}$, which is "good" for all pairs in $S_{Train}$, hence
\begin{equation}
   y^{(i)} = h(x^{(i)}, \mathbf{W}); i = 1,...,m
   \label{eq:model}
\end{equation}
is approximatively valid for all training pair. We call $h(x^{(i)}, \mathbf{W})$ our model with the model weights~$\textbf{W}$. Depending on the on the type of mapping, $\mathbf{W}$ is typically a Matrix and we therefore, write it in bold font. If the learned relation is correct, the model can be used to make predictions on previously unseen input data.\\
If the output, we are trying to predict, is continuous, such as in the housing example, the problem is called a \textbf{regression problem}. We could also have the case where we wanted to predict whether the dwelling is an apartment or a house, given the living area. The predicted output would, therefore, be discrete and we would call this a \textbf{classification problem}.\\
Supervised learning gets its name for the reason that the algorithm always learns on input-output pairs (the outputs typically called labels or targets), and the outputs typically are the result of (laborsome) labeling work done by a person. This is the biggest drawback of supervised learning. There, however, exist ways to use unlabeled data in conjunction with labeled data, referred to as semi-supervised learning. Learning on inputs only corresponds to finding patterns and structures in the input space and is referred to as unsupervised learning. Typical examples for unsupervised learning algorithms are \gls{pca} and $k$-means Clustering~\cite{Goodfellow2016DeepLearning}.\\
For the presented example, one could expect a linear relationship, between the living area of a house and its prize. If this was indeed true, we could make robust predictions with a simple linear model, i.e. $y^{(i)} = h(x^{(i)}, W) = Wx^{(i)} + b$, only incorporating the living area. However, one could argue that the number of rooms or the location, each with its unknown weight, also influence the dwelling's prize. These influencers are typically called features. There was, and still, is a whole science around finding good features to solve learning problems.\\
The main drawback of any learning algorithm relying on features is, however, that the algorithm is inherently constrained by the imagination and ability of the engineer to find and implement good features.

\begin{figure}[htbp]
    \centering
	\includegraphics[width=0.5\textwidth]{supervised_learning}
    \caption[Supervised Learning]{The principle of supervised learning illustrated on the example of predicting house prices (y) depending on the living area (x). Suppose we have $m$ area-price pairs, which we name our training set: $\{(x^{(i)}, y^{(i)}); i = 1,...,m\}$. We let $\chi$ and $\upsilon$ denote the space of input and output values, respectively. In this example, $\chi = \upsilon = \mathbb{R}$. In supervised learning we aim to learn a function (also called mapping) $h : \chi \mapsto \upsilon$, which makes reasonable prize prediction (y) for a given new house area (x). We use the training set to learn $h$. Image and example taken from~\cite{Ng2012StanfordNotes}.}
    \label{fig:dl_supervised}
\end{figure}

\subsection{Training}
In the previous section we defined that the model $h(x^{(i)}, \mathbf{W})$ is parameterized by the set of weights $\textbf{W}$. During the training phase of the model, we adjust $\textbf{W}$ in order for the model to make "better" predictions on the training set. Formally, we want to solve the optimization problem
\begin{equation}
   \mathbf{W}^{*} = \argmin_\textbf{W} \sum_{i=1}^{m} L(h(x^{(i)}, \mathbf{W}), y^{(i)})
   \label{eq:optimization}
\end{equation}
where $L(...)$ denotes a loss function. The loss function is a metric we have to choose, which calculates the error between the correct label $y^{(i)}$ and the prediction our model made. The loss function is often also referred to as cost function. $\mathbf{W}^{*}$ denotes the solution for the mentioned optimization problem and, consequently, is the set of weights which results in the smallest error in our training set. Training of a model corresponds to iteratively decreasing the training error.\\
A loss function typically used for classification problems with $k$ classes, a prediction vector $\mathbf{h}^{(i)}$ and label vector $\mathbf{y}^{(i)}$, is the \textbf{cross-entropy} loss

\begin{equation}
    L(\mathbf{h}^{(i)}, \mathbf{y}^{(i)}) = -\mathbf{y}^{(i)} \log(f(\mathbf{h}^{(i)}))
    \label{eq:cross_entropy_multi}
\end{equation}
with $f(...)$ being the \textbf{softmax} activation function
\begin{equation}
   f(\mathbf{h}^{(i)}) = \frac{\exp\mathbf{h}^{(i)}}{\sum_{j} \exp{\mathbf{h}^{(i)}_{j}}}
   \label{eq:softmax}
\end{equation}
which squashes the predictions into a vector of values between zero and one that add up to one. The corresponding cross-entropy loss for a binary classification problem
\begin{equation}
    L({h}^{(i)}, {y}^{(i)}) = -{y}^{(i)} \log(\sigma({h}^{(i)}))
    \label{eq:cross_entropy_binary}
\end{equation}
with $\sigma(...)$ being the \textbf{sigmoid} activation function
\begin{equation}
   \sigma({h}^{(i)}) = \frac{1}{1 + \exp{(-{h}^{(i)})}}
   \label{eq:sigmoid}
\end{equation}
Another, in deep learning very popular, activation function is the \textbf{\gls{relu}}, defined as
\begin{equation}
   ReLU({h}^{(i)}) = \max(0, {h}^{(i)})
   \label{eq:relu}
\end{equation}

In order to solve Equation~\ref{eq:optimization}, optimizer are used. Optimizer, such as \gls{sgd}~\cite{Goodfellow2016DeepLearning} and Adam~\cite{Kingma2014Adam:Optimization} use the gradient to find $\textbf{W}^*$. The gradient depends on the model and the chosen loss function and corresponds the first-order derivatives of the individual inputs with respect to the outputs.\\

A common problem in machine learning, especially in deep learning, is the problem of under- and overfitting, which is depicted in Figure~\ref{fig:under_over_fitting}. To solve a learning problem, we have to choose a model first. The model's representational power, hence the ability to fit a wide variety of functions, is called capacity~\cite{Goodfellow2016DeepLearning}. If the models capacity is too low for the task at hand, it cannot model the relationship between the input and output. This is called underfitting. On the other hand, if the models capacity is too high, it can start to memorize the data it was trained upon (including the data's statistics) rather than learning structures or relationships. This results in a bad performance on new data, hence bad generalization and is called overfitting.

\begin{figure}[htbp]
    \centering
	\includegraphics[width=0.8\textwidth]{under_over}
    \caption[Under- and Overfitting]{The problem of under- and overfitting. The sample points were generated by random sampling a quadratic function. In the left image, a model with low capacity (a line) is not able to correctly capture the structure of the points. The center image shows that a quadratic model would generalize well to unseen ponts. The right image shows that a 9\textsuperscript{th} degree polynomial would generalize bad to new points despite passing through all points. Image and example taken from~\cite{Goodfellow2016DeepLearning}.}
    \label{fig:under_over_fitting}
\end{figure}

\subsection{Deep Learning \& Convolutional Neural Networks}
With the growing amount of labeled data, gathered in big datasets, and increasing computational performance using \gls{gpu}'s, the creation and training of models, called neural networks, with much larger capacity became possible. Today, some of the biggest datasets for images are ImageNet~\cite{Russakovsky2015ImageNetChallenge} and Microsoft's COCO~\cite{Lin2014MicrosoftContext}.
Neural networks
The most significant advantage of those models was that (given enough training data) it was now possible to train them directly on raw, unprocessed data, rather than on human-engineered features.\\
\gls{cnns}, a class of neural network mostly used to analyze visual imagery, were successfully applied \cite{Lecun2015DeepLearning} and achieved new levels of performances in computer vision tasks and challenges \cite{Krizhevsky2012ImageNetNetworks,Simonyan2014VeryRecognition,Szegedy2014GoingConvolutions,He2015DeepRecognition,Zeiler2014VisualizingNetworks}. 
\gls{cnn}s and neural networks in general, use a cascade of multiple layers of units which can process
and transform data. Each layer takes the previous layer's output as an input. \gls{cnn}s, in contrast to regular neural networks, assume that the input data has some spatial relationship, hence the popular use of \gls{cnn}s for computer vision tasks. Because a \gls{cnn} consists of several sequential convolutional layers, the learned filters deeper in the network can act as detectors for higher semantical features. Therefore it can learn multiple levels of representations, which correspond to multiple levels of abstraction. During training, a \gls{cnn} learns filters which act as detectors for features which are present in the data. It basically builds its internal filter bank to extract information. Figure~\ref{fig:mlearn_weights} shows the learned filters in the first layer of an AlexNet which was trained on ImageNet~\cite{Russakovsky2015ImageNetChallenge}. Note that the learned weights resemble filters for edge or blob detection (sobel operator~\cite{Sobel1990AnOperator}, laplacian of gaussian~\cite{Marr187}) widely used in computer vision.\\
A typical \gls{cnn} is built as a sequence of multiples of the following layers~\cite{KarpathyStanfordRecognition}. Each layer transforms the activations of the previous layer into new activations, through a differentiable function.\\

\textbf{Convolutional Layer:} Layer which contains the learnable weights. The learnable weights form filters, which are used for information extraction. Parameters for a convolutional layer are typically the kernel size of the filters and the number of individual filters (also referred to as channels or features).\\

\textbf{ReLU Layer:} Applies the Equation~\ref{eq:relu} to each of the outputs of the previous layer. This results in thresholding at zero. Other typical activation functions are the sigmoid (Equation~\ref{eq:sigmoid}) or the tanh function.\\

\textbf{Pooling Layer:} A pooling layer performs a down-sampling operation along the spatial dimensions. Typically max-pooling is used, which only lets the maximum activation through. Pooling helps prevent overfitting by reducing the number of parameters in a network.\\

\textbf{Transposed Convolutional Layer:} A transposed convolutional layer performs and up-sampling operation along the spatial dimensions and is typically used as the inverse operation of the pooling layer.\\

\textbf{Dropout layer:} Randomly deactivates some of the activations of the previous layer. Dropout~\cite{Srivastava2014Dropout:Overfitting} helps with the overfitting problem.\\

\textbf{Normalization Layer:} Different types of normalization layers have been proposed, including Batch Normalization~\cite{SergeyIoffe2015BatchNormalization}. They all normalize of the activations in some way.
 
\begin{figure}[htbp]
	\centering
	\subfloat[]
	{
		\label{fig:subfig:mlearn_nn}
		\includegraphics[width=0.48\textwidth]{mlearn_neural_network}
	}
	\hfill
	\subfloat[]
	{
		\label{fig:subfig:mlearn_cnn}
		\includegraphics[width=0.48\textwidth]{mlearn_cnn}
	}
	\caption[Sections of MRN sequences]{\textbf{(a)} Regular neural network where each node of a layer is connected to every node of the previous. \textbf{(b)} CNN where the weights are organized in a \gls{3d} way. Each of the nodes is only locally connected to nodes of the previous layer. The main motivation behind this is that a learned filter (e.g. edge detector) is useful over the whole image. Both Images are from~\cite{KarpathyStanfordRecognition}.}
	\label{fig:mlearn_nn_cnn}  
\end{figure}


\begin{figure}[htbp]
    \centering
	\includegraphics[width=0.8\textwidth]{mlearn_weights}
    \caption[Learned Weights of trained AlexNet]{Learned convolutional filters of the first layer of an AlexNet~\cite{Krizhevsky2012ImageNetNetworks} which was trained on ImageNet. The learned filters act as detectors for high-frequency grayscale features, mostly edges, and low-frequency color features.}
    \label{fig:mlearn_weights}
\end{figure}

\section{Related Work} % =================================================================================
As of today, there is relatively low interest from sides of the scientific community in the segmentation of the nerves of the \gls{pns} as a research topic.\\
Felisaz et al.\cite{Felisaz2016NerveMicro-neurography} propose a semi-automatic method to segment and measure the volumes of different compartments of the tibial nerve based on \gls{mrn} images. They measure fascicular volume, epineural volume, nerve volume and the fascicular to nerve volume ratio (FNR). The also calculated the inter- and intra-observer agreements. They conclude that the method is reproducible and FNR is a novel feature which may help in the diagnosis of neuropathies.
In \cite{Felisaz2017MRNeuropathy.} they further study the assessment of morphometric ultrastructural changes in nerves affected by diabetic peripheral neuropathy. As in their previous work, they use a semiautomated technique of tissue segmentation and to calculate nerve volumes, fascicle volumes, the FNR and the cross-sectional areas (CSA). They noted increased nerve volumes and decreased FNR in patients with diabetic peripheral neuropathy. The fascicle volume was increased in patients with moderate to severe diabetic peripheral neuropathy.
In their recently published work \cite{FelisazTextureNeuropathy} they applied texture analysis to MRN images and concluded that texture analysis might help to discriminate between normal and pathologic nerves.\\
During his master thesis~\cite{Balsiger2016DevelopmentApproaches}, supervisor F. Balsiger investigated the potential use of hand-crafted features for the automatic segmentation of the peripheral nerves done by a trained \gls{rf}~\cite{Breiman2001RandomForests}. The \gls{rf}, also belonging to supervised learning, was trained on hand-crafted features on a dataset consisting of \gls{mrn} images. F. Balsiger continued his work in the field as Balsiger et al. and published two works, proposing a deep learning-based method to segment the peripheral nerves. In both works, a \gls{fcnn} based on the fully-convolutional DenseNet~\cite{Huang2017DenselyNetworks} was trained on MRN images and evaluated. In the first work~\cite{BalsigerContext-awareNeurography}, a semi-automatic approach was investigated, by training the neural network with an additional context feature image, besides the MRN images. For the context feature image, the user annotates the centers of the proximal and distal ends of the sciatic nerve by a single voxel in the MRN image. In case the branching of the sciatic nerve is included in the MRN image, the user annotates its location. The nerve centers for the non-annotated slices are interpolated via first-order B-spline. The final context feature image is obtained by the Euclidean distance from each pixel to the center of the nerve in that slice. They compare the performance to their results of the semi-automatic segmentation of the trained \gls{rf}.
In their second work~\cite{Balsiger2018SegmentationApproach} they propose a fully-automatic \gls{fcnn} method, and compare their results to the inter-rater variability.

\section{Hypothesis} % ===================================================================================
Proposed quantitative biomarkers, such as the cross-sectional area, and the fascicles-to-nerve ratio require a stable and correct segmentation of the peripheral nerve. The segmentation task is tedious and costly.
For this reason, we aim to extract the sciatic nerve of the \gls{pns} automatically from \acrshort{mrn} images, using a deep learning-based approach. Therefore, our first hypothesis is\\

\textit{Deep learning-based segmentation of peripheral nerves from \gls{mrn} images is feasible.} \\

MRN images are \acrlong{3d} and the sciatic nerve is a \acrlong{3d} structure. Hence, our second hypothesis is\\

\textit{3D-Contextual information allows for better segmentation results.}

\section{Aim \& Structure of the Thesis} % ===============================================================
The aim of the thesis is to develop a deep learning-based approach to segment the sciatic nerve from \gls{mrn} images and to investigate the impact of 3D context has on the segmentation performance.\\
\begin{itemize}
    \item Chapter~\ref{chap:methods} presents the materials we used and the methods we applied. It elaborates on how we designed and trained our neural networks, dealt with the problem of overfitting, and how we applied post-processing. Furthermore, the experiments to be conducted are defined.
    \item Chapter~\ref{chap:results} presents all obtained results for the proposed experiments. Further, and more detailed results can also be found in Appendix~\ref{app:results}.
    \item Chapter~\ref{chap:discussion_and_conclusions} discusses the results and conclusions are made.
    \item Chapter~\ref{chap:outlook} presents a visionary outlook.
\end{itemize}

\endinput